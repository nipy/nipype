<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Neuroimaging in Python - Pipelines and Interfaces &mdash; nipy pipeline and interfaces package</title>
    
    <link rel="stylesheet" href="../../_static/nipype.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../',
        VERSION:     '1.0.0dev',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <link rel="author" title="About these documents" href="../../about.html" />
    <link rel="top" title="nipy pipeline and interfaces package" href="../../index.html" />
 
<meta name="keywords" content="nipype, neuroimaging, pipeline, workflow, parallel, python, neuroscience">
<script type="text/javascript">
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-339450-7', 'nipy.org/nipype');
  ga('send', 'pageview');
</script>

  </head>
  <body>
<div class="header-wrapper">
    <div style="background-color: white; text-align: left; padding: 10px 10px 15px 15px">
            <a href="../../index.html">
            <img src="../../_static/nipype-banner-bg.png" alt="NIPY logo"  border="0" />
        <div style="margin-top: 1em;
                border-top: 1px solid #AAA;
                border-bottom: 1px solid #AAA;
                border-radius: 5px;
                padding: 3px 1em;">
            <link rel="stylesheet" href="http://www.google.com/cse/style/look/default.css" type="text/css" />
<style type="text/css">
    a.navbar {
    color: ;
    letter-spacing: .05em;
    font-weight: bold;
        }
</style>

<a class="navbar" href="../../index.html">Home</a> ·
<a class="navbar" href="../../quickstart.html">Quickstart</a> ·
<a class="navbar" href="../../documentation.html">Documentation</a> ·
<a class="navbar" href="../../about.html">Citation</a> ·
<a class="navbar" href="http://nipy.org">NiPy</a>

        </div>
    </div>
</div>

      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
<style type="text/css">
    input.gsc-input {
        border-color: #BCCDF0;
    }
    input.gsc-search-button {
        border-color: #666666;
        background-color: #CECECE;
        padding: 0;
    }
    div.sphinxsidebar .tile {
        border: 1px solid #D1DDE2;
        border-radius: 10px;
        background-color: #E1E8EC;
        padding-left: 0.5em;
        margin: 1em 0;
    }
    div.sphinxsidebar input[type="text"] {
        width: 100%;
    }
    div.sphinxsidebar input[type="submit"] {
        width: 100%;
    }
</style>

<div class="sidebarblock">
    <div id="cse-search-form">Loading</div>

    <script src="http://www.google.com/jsapi" type="text/javascript"></script>
    <script type="text/javascript">
        google.load('search', '1', {language : 'en'});
        google.setOnLoadCallback(function() {
            var customSearchControl = new google.search.CustomSearchControl(
                    '010960497803984932957:u8pmqf7fdoq');

            customSearchControl.setResultSetSize(google.search.Search.FILTERED_CSE_RESULTSET);
            var options = new google.search.DrawOptions();
            options.enableSearchboxOnly("../../searchresults.html");
            customSearchControl.draw('cse-search-form', options);
        }, true);
    </script>
</div>

  <h3><a href="../../index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">interfaces.ants.segmentation</a><ul>
<li><a class="reference internal" href="#atropos">Atropos</a><ul>
<li><a class="reference internal" href="#examples">Examples</a></li>
</ul>
</li>
<li><a class="reference internal" href="#jointfusion">JointFusion</a><ul>
<li><a class="reference internal" href="#id1">Examples</a></li>
</ul>
</li>
<li><a class="reference internal" href="#laplacianthickness">LaplacianThickness</a><ul>
<li><a class="reference internal" href="#id2">Examples</a></li>
</ul>
</li>
<li><a class="reference internal" href="#n4biasfieldcorrection">N4BiasFieldCorrection</a><ul>
<li><a class="reference internal" href="#id4">Examples</a></li>
</ul>
</li>
<li><a class="reference internal" href="#antscorticalthickness">antsCorticalThickness</a><ul>
<li><a class="reference internal" href="#id5">Examples</a></li>
</ul>
</li>
</ul>
</li>
</ul>

<style type="text/css">
    div.sphinxsidebar .tile {
        border: 1px solid #D1DDE2;
        border-radius: 10px;
        background-color: #E1E8EC;
        padding-left: 0.5em;
        margin: 1em 0;
    }
</style>
<div class="sidebarblock">
    <h3>Versions</h3>

    <div class="tile">
        <table style="width: 100%;">
            <tr style="font-weight: bold;">
                <td align="left">Release</td><td align="right">Devel</td>
            </tr>
            <tr>
                <td align="left">0.10.0</td><td align="right">1.0-dev</td>
            </tr>
            <tr>
                <td align="left"><a href="../../users/install.html">Download</a></td>
                <td align="right"><a href="https://github.com/nipy/nipype">Github</a></td>
            </tr>
        </table>
    </div>

    <div id="buttons">
        <div id="ohloh-use" style="margin-right: 25px; margin-top: -2px; float: left;">
            <script type="text/javascript"
                    src="http://www.ohloh.net/p/480871/widgets/project_users_logo.js">
            </script>
        </div><!-- use -->
        <g:plusone size="medium" annotation="none"></g:plusone>
        <div class="clear"></div>
    </div><!-- buttons container -->
</div>


<script type="text/javascript">
    (function() {
        var po = document.createElement('script'); po.type = 'text/javascript'; po.async = true;
        po.src = 'https://apis.google.com/js/plusone.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(po, s);
    })();
</script>

<h3>Links</h3>

<ul>
    <li>Docs: <a href="http://nipy.org/nipype">Stable</a> · <a href="http://www.mit.edu/~satra/nipype-nightly/">Nightly</a></li>
    <li>Code: <a href="http://github.com/nipy/nipype">Github</a> · <a href="http://github.com/nipy/nipype/issues">Bugs-Requests</a></li>
    <li>Forum: <a href="http://neurostars.org/t/nipype">User</a> · <a href="http://projects.scipy.org/mailman/listinfo/nipy-devel">Developer</a></li>
    <li><a href="http://nipy.org/software/license/index.html"><img src="https://pypip.in/license/nipype/badge.png" alt="License"></a> · <a href="http://nipy.org/about/funding.html">Funding</a></li>
    <li><a href="https://travis-ci.org/nipy/nipype"><img src="https://travis-ci.org/nipy/nipype.png?branch=master" alt="travis"></a> · <a href='https://coveralls.io/r/nipy/nipype'><img src='https://coveralls.io/repos/nipy/nipype/badge.png' alt='Coverage Status' /></a></li>
    <li><a href="https://pypi.python.org/pypi/nipype/"><img src="https://pypip.in/download/nipype/badge.png" alt="Downloads"></a> · <a href='https://pypi.python.org/pypi/nipype/'><img src='https://pypip.in/py_versions/nipype/badge.png' alt='Python Versions' /></a></li>
</ul>


        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="interfaces-ants-segmentation">
<h1>interfaces.ants.segmentation<a class="headerlink" href="#interfaces-ants-segmentation" title="Permalink to this headline">¶</a></h1>
<span class="target" id="nipype-interfaces-ants-segmentation-atropos"></span><div class="section" id="atropos">
<span id="index-0"></span><h2>Atropos<a class="headerlink" href="#atropos" title="Permalink to this headline">¶</a></h2>
<p><a class="reference external" href="http://github.com/nipy/nipype/tree/3444b7588a1dea15675dc8a4f5be5f8b753adbd8/nipype/interfaces/ants/segmentation.py#L57">Link to code</a></p>
<p>Wraps command <strong>Atropos</strong></p>
<p>A finite mixture modeling (FMM) segmentation approach with possibilities for
specifying prior constraints. These prior constraints include the specification
of a prior label image, prior probability images (one for each class), and/or an
MRF prior to enforce spatial smoothing of the labels. Similar algorithms include
FAST and SPM.</p>
<div class="section" id="examples">
<h3>Examples<a class="headerlink" href="#examples" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">nipype.interfaces.ants</span> <span class="kn">import</span> <span class="n">Atropos</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">at</span> <span class="o">=</span> <span class="n">Atropos</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">at</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">dimension</span> <span class="o">=</span> <span class="mi">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">at</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">intensity_images</span> <span class="o">=</span> <span class="s">&#39;structural.nii&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">at</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">mask_image</span> <span class="o">=</span> <span class="s">&#39;mask.nii&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">at</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">initialization</span> <span class="o">=</span> <span class="s">&#39;PriorProbabilityImages&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">at</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">prior_probability_images</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;rc1s1.nii&#39;</span><span class="p">,</span> <span class="s">&#39;rc1s2.nii&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">at</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">number_of_tissue_classes</span> <span class="o">=</span> <span class="mi">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">at</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">prior_weighting</span> <span class="o">=</span> <span class="mf">0.8</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">at</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">prior_probability_threshold</span> <span class="o">=</span> <span class="mf">0.0000001</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">at</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">likelihood_model</span> <span class="o">=</span> <span class="s">&#39;Gaussian&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">at</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">mrf_smoothing_factor</span> <span class="o">=</span> <span class="mf">0.2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">at</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">mrf_radius</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">at</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">icm_use_synchronous_update</span> <span class="o">=</span> <span class="bp">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">at</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">maximum_number_of_icm_terations</span> <span class="o">=</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">at</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">n_iterations</span> <span class="o">=</span> <span class="mi">5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">at</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">convergence_threshold</span> <span class="o">=</span> <span class="mf">0.000001</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">at</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">posterior_formulation</span> <span class="o">=</span> <span class="s">&#39;Socrates&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">at</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">use_mixture_model_proportions</span> <span class="o">=</span> <span class="bp">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">at</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">save_posteriors</span> <span class="o">=</span> <span class="bp">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">at</span><span class="o">.</span><span class="n">cmdline</span>
<span class="go">&#39;Atropos --image-dimensionality 3 --icm [1,1] --initialization PriorProbabilityImages[2,priors/priorProbImages%02d.nii,0.8,1e-07] --intensity-image structural.nii --likelihood-model Gaussian --mask-image mask.nii --mrf [0.2,1x1x1] --convergence [5,1e-06] --output [structural_labeled.nii,POSTERIOR_%02d.nii.gz] --posterior-formulation Socrates[1]&#39;</span>
</pre></div>
</div>
<p>Inputs:</p>
<div class="highlight-python"><div class="highlight"><pre>[Mandatory]
initialization: (&#39;Random&#39; or &#39;Otsu&#39; or &#39;KMeans&#39; or
         &#39;PriorProbabilityImages&#39; or &#39;PriorLabelImage&#39;)
        flag: %s
        requires: number_of_tissue_classes
intensity_images: (a list of items which are an existing file name)
        flag: --intensity-image %s...
mask_image: (an existing file name)
        flag: --mask-image %s
number_of_tissue_classes: (an integer)

[Optional]
args: (a string)
        Additional parameters to the command
        flag: %s
convergence_threshold: (a float)
        requires: n_iterations
dimension: (3 or 2 or 4, nipype default value: 3)
        image dimension (2, 3, or 4)
        flag: --image-dimensionality %d
environ: (a dictionary with keys which are a value of type &#39;str&#39; and
         with values which are a value of type &#39;str&#39;, nipype default value:
         {})
        Environment variables
icm_use_synchronous_update: (a boolean)
        flag: %s
ignore_exception: (a boolean, nipype default value: False)
        Print an error message instead of throwing an exception in case the
        interface fails to run
likelihood_model: (a string)
        flag: --likelihood-model %s
maximum_number_of_icm_terations: (an integer)
        requires: icm_use_synchronous_update
mrf_radius: (a list of items which are an integer)
        requires: mrf_smoothing_factor
mrf_smoothing_factor: (a float)
        flag: %s
n_iterations: (an integer)
        flag: %s
num_threads: (an integer, nipype default value: 1)
        Number of ITK threads to use
out_classified_image_name: (a file name)
        flag: %s
output_posteriors_name_template: (a string, nipype default value:
         POSTERIOR_%02d.nii.gz)
posterior_formulation: (a string)
        flag: %s
prior_probability_images: (a list of items which are an existing file
         name)
prior_probability_threshold: (a float)
        requires: prior_weighting
prior_weighting: (a float)
save_posteriors: (a boolean)
terminal_output: (&#39;stream&#39; or &#39;allatonce&#39; or &#39;file&#39; or &#39;none&#39;)
        Control terminal output: `stream` - displays to terminal immediately
        (default), `allatonce` - waits till command is finished to display
        output, `file` - writes output to file, `none` - output is ignored
use_mixture_model_proportions: (a boolean)
        requires: posterior_formulation
</pre></div>
</div>
<p>Outputs:</p>
<div class="highlight-python"><div class="highlight"><pre>classified_image: (an existing file name)
posteriors: (a list of items which are a file name)
</pre></div>
</div>
<span class="target" id="nipype-interfaces-ants-segmentation-jointfusion"></span></div>
</div>
<div class="section" id="jointfusion">
<span id="index-1"></span><h2>JointFusion<a class="headerlink" href="#jointfusion" title="Permalink to this headline">¶</a></h2>
<p><a class="reference external" href="http://github.com/nipy/nipype/tree/3444b7588a1dea15675dc8a4f5be5f8b753adbd8/nipype/interfaces/ants/segmentation.py#L599">Link to code</a></p>
<p>Wraps command <strong>jointfusion</strong></p>
<div class="section" id="id1">
<h3>Examples<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">nipype.interfaces.ants</span> <span class="kn">import</span> <span class="n">JointFusion</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">at</span> <span class="o">=</span> <span class="n">JointFusion</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">at</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">dimension</span> <span class="o">=</span> <span class="mi">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">at</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">modalities</span> <span class="o">=</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">at</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">method</span> <span class="o">=</span> <span class="s">&#39;Joint[0.1,2]&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">at</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">output_label_image</span> <span class="o">=</span><span class="s">&#39;fusion_labelimage_output.nii&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">at</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">warped_intensity_images</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;im1.nii&#39;</span><span class="p">,</span>
<span class="gp">... </span>                                     <span class="s">&#39;im2.nii&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">at</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">warped_label_images</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;segmentation0.nii.gz&#39;</span><span class="p">,</span>
<span class="gp">... </span>                                 <span class="s">&#39;segmentation1.nii.gz&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">at</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">target_image</span> <span class="o">=</span> <span class="s">&#39;T1.nii&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">at</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">patch_radius</span> <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">at</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">search_radius</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">at</span><span class="o">.</span><span class="n">cmdline</span>
<span class="go">&#39;jointfusion 3 1 -m Joint[0.1,2] -rp 3x2x1 -rs 1x2x3 -tg T1.nii -g im1.nii -g im2.nii -l segmentation0.nii.gz -l segmentation1.nii.gz fusion_labelimage_output.nii&#39;</span>
</pre></div>
</div>
<p>Alternately, you can specify the voting method and parameters more &#8216;Pythonically&#8217;:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">at</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">method</span> <span class="o">=</span> <span class="s">&#39;Joint&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">at</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">at</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">beta</span> <span class="o">=</span> <span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">at</span><span class="o">.</span><span class="n">cmdline</span>
<span class="go">&#39;jointfusion 3 1 -m Joint[0.5,1] -rp 3x2x1 -rs 1x2x3 -tg T1.nii -g im1.nii -g im2.nii -l segmentation0.nii.gz -l segmentation1.nii.gz fusion_labelimage_output.nii&#39;</span>
</pre></div>
</div>
<p>Inputs:</p>
<div class="highlight-python"><div class="highlight"><pre>[Mandatory]
dimension: (3 or 2 or 4, nipype default value: 3)
        image dimension (2, 3, or 4)
        flag: %d, position: 0
modalities: (an integer)
        Number of modalities or features
        flag: %d, position: 1
output_label_image: (a file name)
        Output fusion label map image
        flag: %s, position: -1
target_image: (a list of items which are an existing file name)
        Target image(s)
        flag: -tg %s...
warped_intensity_images: (a list of items which are an existing file
         name)
        Warped atlas images
        flag: -g %s...
warped_label_images: (a list of items which are an existing file
         name)
        Warped atlas segmentations
        flag: -l %s...

[Optional]
alpha: (a float, nipype default value: 0.0)
        Regularization term added to matrix Mx for inverse
        requires: method
args: (a string)
        Additional parameters to the command
        flag: %s
atlas_group_id: (a list of items which are a value of type &#39;int&#39;)
        Assign a group ID for each atlas
        flag: -gp %d...
atlas_group_weights: (a list of items which are a value of type
         &#39;int&#39;)
        Assign the voting weights to each atlas group
        flag: -gpw %d...
beta: (an integer, nipype default value: 0)
        Exponent for mapping intensity difference to joint error
        requires: method
environ: (a dictionary with keys which are a value of type &#39;str&#39; and
         with values which are a value of type &#39;str&#39;, nipype default value:
         {})
        Environment variables
exclusion_region: (an existing file name)
        Specify an exclusion region for the given label.
        flag: -x %s
ignore_exception: (a boolean, nipype default value: False)
        Print an error message instead of throwing an exception in case the
        interface fails to run
method: (a string, nipype default value: )
        Select voting method. Options: Joint (Joint Label Fusion). May be
        followed by optional parameters in brackets, e.g., -m Joint[0.1,2]
        flag: -m %s
num_threads: (an integer, nipype default value: 1)
        Number of ITK threads to use
output_posteriors_name_template: (a string)
        Save the posterior maps (probability that each voxel belongs to each
        label) as images. The number of images saved equals the number of
        labels. The filename pattern must be in C printf format, e.g.
        posterior%04d.nii.gz
        flag: -p %s
output_voting_weights_name_template: (a string)
        Save the voting weights as images. The number of images saved equals
        the number of atlases. The filename pattern must be in C printf
        format, e.g. weight%04d.nii.gz
        flag: -w %s
patch_radius: (a list of items which are a value of type &#39;int&#39;)
        Patch radius for similarity measures, scalar or vector. Default:
        2x2x2
        flag: -rp %s
search_radius: (a list of items which are a value of type &#39;int&#39;)
        Local search radius. Default: 3x3x3
        flag: -rs %s
terminal_output: (&#39;stream&#39; or &#39;allatonce&#39; or &#39;file&#39; or &#39;none&#39;)
        Control terminal output: `stream` - displays to terminal immediately
        (default), `allatonce` - waits till command is finished to display
        output, `file` - writes output to file, `none` - output is ignored
</pre></div>
</div>
<p>Outputs:</p>
<div class="highlight-python"><div class="highlight"><pre>output_label_image: (an existing file name)
</pre></div>
</div>
<span class="target" id="nipype-interfaces-ants-segmentation-laplacianthickness"></span></div>
</div>
<div class="section" id="laplacianthickness">
<span id="index-2"></span><h2>LaplacianThickness<a class="headerlink" href="#laplacianthickness" title="Permalink to this headline">¶</a></h2>
<p><a class="reference external" href="http://github.com/nipy/nipype/tree/3444b7588a1dea15675dc8a4f5be5f8b753adbd8/nipype/interfaces/ants/segmentation.py#L186">Link to code</a></p>
<p>Wraps command <strong>LaplacianThickness</strong></p>
<p>Calculates the cortical thickness from an anatomical image</p>
<div class="section" id="id2">
<h3>Examples<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">nipype.interfaces.ants</span> <span class="kn">import</span> <span class="n">LaplacianThickness</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cort_thick</span> <span class="o">=</span> <span class="n">LaplacianThickness</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cort_thick</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">input_wm</span> <span class="o">=</span> <span class="s">&#39;white_matter.nii.gz&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cort_thick</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">input_gm</span> <span class="o">=</span> <span class="s">&#39;gray_matter.nii.gz&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cort_thick</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">output_image</span> <span class="o">=</span> <span class="s">&#39;output_thickness.nii.gz&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cort_thick</span><span class="o">.</span><span class="n">cmdline</span>
<span class="go">&#39;LaplacianThickness white_matter.nii.gz gray_matter.nii.gz output_thickness.nii.gz&#39;</span>
</pre></div>
</div>
<p>Inputs:</p>
<div class="highlight-python"><div class="highlight"><pre>[Mandatory]
input_gm: (a file name)
        gray matter segmentation image
        flag: %s, position: 2
input_wm: (a file name)
        white matter segmentation image
        flag: %s, position: 1

[Optional]
args: (a string)
        Additional parameters to the command
        flag: %s
dT: (a float)
        flag: dT=%d, position: 6
environ: (a dictionary with keys which are a value of type &#39;str&#39; and
         with values which are a value of type &#39;str&#39;, nipype default value:
         {})
        Environment variables
ignore_exception: (a boolean, nipype default value: False)
        Print an error message instead of throwing an exception in case the
        interface fails to run
num_threads: (an integer, nipype default value: 1)
        Number of ITK threads to use
opt_tolerance: (a float)
        flag: optional-laplacian-tolerance=%d, position: 8
output_image: (a file name)
        name of output file
        flag: %s, position: 3
prior_thickness: (a float)
        flag: priorthickval=%d, position: 5
smooth_param: (a float)
        flag: smoothparam=%d, position: 4
sulcus_prior: (a boolean)
        flag: use-sulcus-prior, position: 7
terminal_output: (&#39;stream&#39; or &#39;allatonce&#39; or &#39;file&#39; or &#39;none&#39;)
        Control terminal output: `stream` - displays to terminal immediately
        (default), `allatonce` - waits till command is finished to display
        output, `file` - writes output to file, `none` - output is ignored
</pre></div>
</div>
<p>Outputs:</p>
<div class="highlight-python"><div class="highlight"><pre>output_image: (an existing file name)
        Cortical thickness
</pre></div>
</div>
<span class="target" id="nipype-interfaces-ants-segmentation-n4biasfieldcorrection"></span></div>
</div>
<div class="section" id="n4biasfieldcorrection">
<span id="index-3"></span><h2>N4BiasFieldCorrection<a class="headerlink" href="#n4biasfieldcorrection" title="Permalink to this headline">¶</a></h2>
<p><a class="reference external" href="http://github.com/nipy/nipype/tree/3444b7588a1dea15675dc8a4f5be5f8b753adbd8/nipype/interfaces/ants/segmentation.py#L255">Link to code</a></p>
<p>Wraps command <strong>N4BiasFieldCorrection</strong></p>
<p>N4 is a variant of the popular N3 (nonparameteric nonuniform normalization)
retrospective bias correction algorithm. Based on the assumption that the
corruption of the low frequency bias field can be modeled as a convolution of
the intensity histogram by a Gaussian, the basic algorithmic protocol is to
iterate between deconvolving the intensity histogram by a Gaussian, remapping
the intensities, and then spatially smoothing this result by a B-spline modeling
of the bias field itself. The modifications from and improvements obtained over
the original N3 algorithm are described in <a class="reference internal" href="#tustison2010" id="id3">[Tustison2010]</a>.</p>
<table class="docutils citation" frame="void" id="tustison2010" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id3">[Tustison2010]</a></td><td>N. Tustison et al.,
N4ITK: Improved N3 Bias Correction, IEEE Transactions on Medical Imaging,
29(6):1310-1320, June 2010.</td></tr>
</tbody>
</table>
<div class="section" id="id4">
<h3>Examples<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">copy</span>
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">nipype.interfaces.ants</span> <span class="kn">import</span> <span class="n">N4BiasFieldCorrection</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">n4</span> <span class="o">=</span> <span class="n">N4BiasFieldCorrection</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">n4</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">dimension</span> <span class="o">=</span> <span class="mi">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">n4</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">input_image</span> <span class="o">=</span> <span class="s">&#39;structural.nii&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">n4</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">bspline_fitting_distance</span> <span class="o">=</span> <span class="mi">300</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">n4</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">shrink_factor</span> <span class="o">=</span> <span class="mi">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">n4</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">n_iterations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">50</span><span class="p">,</span><span class="mi">50</span><span class="p">,</span><span class="mi">30</span><span class="p">,</span><span class="mi">20</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">n4</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">convergence_threshold</span> <span class="o">=</span> <span class="mf">1e-6</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">n4</span><span class="o">.</span><span class="n">cmdline</span>
<span class="go">&#39;N4BiasFieldCorrection --bspline-fitting [ 300 ] --image-dimension 3 --input-image structural.nii --convergence [ 50x50x30x20, 1e-06 ] --output structural_corrected.nii --shrink-factor 3&#39;</span>
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">n4_2</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">n4</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">n4_2</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">bspline_order</span> <span class="o">=</span> <span class="mi">5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">n4_2</span><span class="o">.</span><span class="n">cmdline</span>
<span class="go">&#39;N4BiasFieldCorrection --bspline-fitting [ 300, 5 ] --image-dimension 3 --input-image structural.nii --convergence [ 50x50x30x20, 1e-06 ] --output structural_corrected.nii --shrink-factor 3&#39;</span>
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">n4_3</span> <span class="o">=</span> <span class="n">N4BiasFieldCorrection</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">n4_3</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">input_image</span> <span class="o">=</span> <span class="s">&#39;structural.nii&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">n4_3</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">save_bias</span> <span class="o">=</span> <span class="bp">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">n4_3</span><span class="o">.</span><span class="n">cmdline</span>
<span class="go">&#39;N4BiasFieldCorrection --image-dimension 3 --input-image structural.nii --output [ structural_corrected.nii, structural_bias.nii ]&#39;</span>
</pre></div>
</div>
<p>Inputs:</p>
<div class="highlight-python"><div class="highlight"><pre>[Mandatory]
input_image: (a file name)
        image to apply transformation to (generally a coregistered
        functional)
        flag: --input-image %s
save_bias: (a boolean, nipype default value: False)
        True if the estimated bias should be saved to file.
        mutually_exclusive: bias_image

[Optional]
args: (a string)
        Additional parameters to the command
        flag: %s
bias_image: (a file name)
        Filename for the estimated bias.
bspline_fitting_distance: (a float)
        flag: --bspline-fitting %s
bspline_order: (an integer)
        requires: bspline_fitting_distance
convergence_threshold: (a float)
        requires: n_iterations
dimension: (3 or 2, nipype default value: 3)
        image dimension (2 or 3)
        flag: --image-dimension %d
environ: (a dictionary with keys which are a value of type &#39;str&#39; and
         with values which are a value of type &#39;str&#39;, nipype default value:
         {})
        Environment variables
ignore_exception: (a boolean, nipype default value: False)
        Print an error message instead of throwing an exception in case the
        interface fails to run
mask_image: (a file name)
        flag: --mask-image %s
n_iterations: (a list of items which are an integer)
        flag: --convergence %s
        requires: convergence_threshold
num_threads: (an integer, nipype default value: 1)
        Number of ITK threads to use
output_image: (a string)
        output file name
        flag: --output %s
shrink_factor: (an integer)
        flag: --shrink-factor %d
terminal_output: (&#39;stream&#39; or &#39;allatonce&#39; or &#39;file&#39; or &#39;none&#39;)
        Control terminal output: `stream` - displays to terminal immediately
        (default), `allatonce` - waits till command is finished to display
        output, `file` - writes output to file, `none` - output is ignored
weight_image: (a file name)
        flag: --weight-image %s
</pre></div>
</div>
<p>Outputs:</p>
<div class="highlight-python"><div class="highlight"><pre>bias_image: (an existing file name)
        Estimated bias
output_image: (an existing file name)
        Warped image
</pre></div>
</div>
<span class="target" id="nipype-interfaces-ants-segmentation-antscorticalthickness"></span></div>
</div>
<div class="section" id="antscorticalthickness">
<span id="index-4"></span><h2>antsCorticalThickness<a class="headerlink" href="#antscorticalthickness" title="Permalink to this headline">¶</a></h2>
<p><a class="reference external" href="http://github.com/nipy/nipype/tree/3444b7588a1dea15675dc8a4f5be5f8b753adbd8/nipype/interfaces/ants/segmentation.py#L463">Link to code</a></p>
<p>Wraps command <strong>antsCorticalThickness.sh</strong></p>
<div class="section" id="id5">
<h3>Examples<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">nipype.interfaces.ants.segmentation</span> <span class="kn">import</span> <span class="n">antsCorticalThickness</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">corticalthickness</span> <span class="o">=</span> <span class="n">antsCorticalThickness</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">corticalthickness</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">dimension</span> <span class="o">=</span> <span class="mi">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">corticalthickness</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">anatomical_image</span> <span class="o">=</span><span class="s">&#39;T1.nii.gz&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">corticalthickness</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">brain_template</span> <span class="o">=</span> <span class="s">&#39;study_template.nii.gz&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">corticalthickness</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">brain_probability_mask</span> <span class="o">=</span><span class="s">&#39;ProbabilityMaskOfStudyTemplate.nii.gz&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">corticalthickness</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">segmentation_priors</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;BrainSegmentationPrior01.nii.gz&#39;</span><span class="p">,</span> <span class="s">&#39;BrainSegmentationPrior02.nii.gz&#39;</span><span class="p">,</span> <span class="s">&#39;BrainSegmentationPrior03.nii.gz&#39;</span><span class="p">,</span> <span class="s">&#39;BrainSegmentationPrior04.nii.gz&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">corticalthickness</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">t1_registration_template</span> <span class="o">=</span> <span class="s">&#39;brain_study_template.nii.gz&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">corticalthickness</span><span class="o">.</span><span class="n">cmdline</span>
<span class="go">&#39;antsCorticalThickness.sh -a T1.nii.gz -m ProbabilityMaskOfStudyTemplate.nii.gz -e study_template.nii.gz -d 3 -s nii.gz -o antsCT_ -p nipype_priors/BrainSegmentationPrior%02d.nii.gz -t brain_study_template.nii.gz&#39;</span>
</pre></div>
</div>
<p>Inputs:</p>
<div class="highlight-python"><div class="highlight"><pre>[Mandatory]
anatomical_image: (an existing file name)
        Structural *intensity* image, typically T1.If more than one
        anatomical image is specified,subsequently specified images are used
        during thesegmentation process. However, only the firstimage is used
        in the registration of priors.Our suggestion would be to specify the
        T1as the first image.
        flag: -a %s
brain_probability_mask: (an existing file name)
        brain probability mask in template space
        flag: -m %s
brain_template: (an existing file name)
        Anatomical *intensity* template (possibly created using apopulation
        data set with buildtemplateparallel.sh in ANTs).This template is
        *not* skull-stripped.
        flag: -e %s
segmentation_priors: (a list of items which are an existing file
         name)
        flag: -p %s
t1_registration_template: (an existing file name)
        Anatomical *intensity* template(assumed to be skull-stripped). A
        commoncase would be where this would be the sametemplate as
        specified in the -e option whichis not skull stripped.
        flag: -t %s

[Optional]
args: (a string)
        Additional parameters to the command
        flag: %s
b_spline_smoothing: (a boolean)
        Use B-spline SyN for registrations and B-splineexponential mapping
        in DiReCT.
        flag: -v
cortical_label_image: (an existing file name)
        Cortical ROI labels to use as a prior for ATITH.
debug: (a boolean)
        If &gt; 0, runs a faster version of the script.Only for testing.
        Implies -u 0.Requires single thread computation for complete
        reproducibility.
        flag: -z 1
dimension: (3 or 2, nipype default value: 3)
        image dimension (2 or 3)
        flag: -d %d
environ: (a dictionary with keys which are a value of type &#39;str&#39; and
         with values which are a value of type &#39;str&#39;, nipype default value:
         {})
        Environment variables
extraction_registration_mask: (an existing file name)
        Mask (defined in the template space) used during registration for
        brain extraction.
        flag: -f %s
ignore_exception: (a boolean, nipype default value: False)
        Print an error message instead of throwing an exception in case the
        interface fails to run
image_suffix: (a string, nipype default value: nii.gz)
        any of standard ITK formats, nii.gz is default
        flag: -s %s
keep_temporary_files: (an integer)
        Keep brain extraction/segmentation warps, etc (default = 0).
        flag: -k %d
label_propagation: (a string)
        Incorporate a distance prior one the posterior formulation. Should
        beof the form &#39;label[lambda,boundaryProbability]&#39; where labelis a
        value of 1,2,3,... denoting label ID. The labelprobability for
        anything outside the current label = boundaryProbability * exp(
        -lambda * distanceFromBoundary )Intuitively, smaller lambda values
        will increase the spatial capturerange of the distance prior. To
        apply to all label values, simply omitspecifying the label, i.e. -l
        [lambda,boundaryProbability].
        flag: -l %s
max_iterations: (an integer)
        ANTS registration max iterations(default = 100x100x70x20)
        flag: -i %d
num_threads: (an integer, nipype default value: 1)
        Number of ITK threads to use
out_prefix: (a string, nipype default value: antsCT_)
        Prefix that is prepended to all output files (default = antsCT_)
        flag: -o %s
posterior_formulation: (a string)
        Atropos posterior formulation and whether or notto use mixture model
        proportions.e.g &#39;Socrates[1]&#39; (default) or &#39;Aristotle[1]&#39;.Choose the
        latter if youwant use the distance priors (see also the -l optionfor
        label propagation control).
        flag: -b %s
prior_segmentation_weight: (a float)
        Atropos spatial prior *probability* weight forthe segmentation
        flag: -w %f
quick_registration: (a boolean)
        If = 1, use antsRegistrationSyNQuick.sh as the basis for
        registrationduring brain extraction, brain segmentation,
        and(optional) normalization to a template.Otherwise use
        antsRegistrationSyN.sh (default = 0).
        flag: -q 1
segmentation_iterations: (an integer)
        N4 -&gt; Atropos -&gt; N4 iterations during segmentation(default = 3)
        flag: -n %d
terminal_output: (&#39;stream&#39; or &#39;allatonce&#39; or &#39;file&#39; or &#39;none&#39;)
        Control terminal output: `stream` - displays to terminal immediately
        (default), `allatonce` - waits till command is finished to display
        output, `file` - writes output to file, `none` - output is ignored
use_floatingpoint_precision: (0 or 1)
        Use floating point precision in registrations (default = 0)
        flag: -j %d
use_random_seeding: (0 or 1)
        Use random number generated from system clock in Atropos(default =
        1)
        flag: -u %d
</pre></div>
</div>
<p>Outputs:</p>
<div class="highlight-python"><div class="highlight"><pre>BrainExtractionMask: (an existing file name)
        brain extraction mask
BrainSegmentation: (an existing file name)
        brain segmentaion image
BrainSegmentationN4: (an existing file name)
        N4 corrected image
BrainSegmentationPosteriors: (a list of items which are an existing
         file name)
        Posterior probability images
BrainVolumes: (an existing file name)
        Brain volumes as text
CorticalThickness: (an existing file name)
        cortical thickness file
CorticalThicknessNormedToTemplate: (an existing file name)
        Normalized cortical thickness
SubjectToTemplate0GenericAffine: (an existing file name)
        Template to subject inverse affine
SubjectToTemplate1Warp: (an existing file name)
        Template to subject inverse warp
SubjectToTemplateLogJacobian: (an existing file name)
        Template to subject log jacobian
TemplateToSubject0Warp: (an existing file name)
        Template to subject warp
TemplateToSubject1GenericAffine: (an existing file name)
        Template to subject affine
</pre></div>
</div>
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>

    <div class="footer">
        &copy; Copyright 2009-14, Neuroimaging in Python team.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.2.3.
    </div>
<div class="footer">This page uses <a href="http://analytics.google.com/">
Google Analytics</a> to collect statistics. You can disable it by blocking
the JavaScript coming from www.google-analytics.com.
</div>

  </body>
</html>